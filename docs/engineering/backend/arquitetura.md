# Arquitetura de Streaming e Performance

Esta seÃ§Ã£o descreve as decisÃµes de engenharia que permitem ao **DataProfiler** processar arquivos massivos (GBs) mantendo uma pegada de memÃ³ria mÃ­nima (MBs).  
A arquitetura resolve o problema clÃ¡ssico de **Big Data em Hardware Pequeno**.

---

## ğŸ¯ 1. O Desafio de Engenharia

Em abordagens tradicionais de CiÃªncia de Dados (como Python/Pandas ou R), o padrÃ£o Ã© carregar todo o dataset na memÃ³ria RAM (_In-Memory Processing_).

!!! danger "CenÃ¡rio Tradicional"

    - **Arquivo de entrada:** CSV de 10 GB
    - **Infraestrutura:** Container serverless (Render, AWS Lambda) com **512 MB de RAM**
    - **Resultado:** Processo encerrado com erro `OOMKilled` antes da anÃ¡lise comeÃ§ar

!!! success "Abordagem DataProfiler"

    Adotamos uma arquitetura de **Streaming Pipeline**.
    Em vez de carregar o dataset inteiro, os dados sÃ£o tratados como um **fluxo contÃ­nuo**:

    > LÃª â†’ Processa â†’ Descarta da memÃ³ria

## ğŸ”„ 2. Pipeline de Processamento

O fluxo de dados segue o padrÃ£o **Producerâ€“Consumer**, utilizando as primitivas de concorrÃªncia do Go (`Channels` e `Goroutines`).

```mermaid
graph LR
    User[UsuÃ¡rio] -->|Upload HTTP Multipart| Server[Servidor Go]

    subgraph "Camada de IngestÃ£o (I/O)"
        Server -->|Stream 32MB chunks| Disk[Disco TemporÃ¡rio]
        Disk -->|Buffer 1MB| Reader[Leitor Bufio]
        Reader -->|Parse CSV| Parser[CSV Parser]
    end

    subgraph "Camada de Processamento (ConcorrÃªncia)"
        Parser -->|Envia Linha| Chan{Channel Buffer: 1000}

        Chan -->|Consome| W1[Worker 1: InferÃªncia]
        Chan -->|Consome| W2[Worker 2: EstatÃ­stica]
        Chan -->|Consome| W3[Worker 3: Regex PII]
    end

    subgraph "Camada de AgregaÃ§Ã£o"
        W1 & W2 & W3 -->|Resultados Parciais| Agg[Acumulador]
        Agg -->|JSON Final| UI[Frontend React]
    end
```

---

## âš™ï¸ 3. Tuning de Performance

### Os â€œNÃºmeros MÃ¡gicosâ€

A eficiÃªncia do sistema depende do ajuste preciso de buffers e limites.
Abaixo estÃ£o as principais decisÃµes tÃ©cnicas.

---

### ğŸ“€ 3.1 OtimizaÃ§Ã£o de I/O de Disco (`bufio`)

Ler dados do disco Ã© uma operaÃ§Ã£o lenta.
A leitura byte a byte gera milhÃµes de _syscalls_, degradando a performance.

=== "ImplementaÃ§Ã£o"

    bufio.NewReaderSize(file, 1024\*1024)

=== "DecisÃ£o TÃ©cnica"

    - Buffer de **1 MB**
    - Reduz drasticamente o nÃºmero de acessos ao disco
    - Aumenta o throughput de leitura

---

### ğŸ“¤ 3.2 Limite de Upload (Multipart Form)

Uploads grandes podem esgotar a memÃ³ria do servidor se nÃ£o houver controle.

=== "ImplementaÃ§Ã£o"

    ```go
    r.ParseMultipartForm(32 << 20)
    ```

=== "DecisÃ£o TÃ©cnica"

    - Apenas **32 MB** permanecem em RAM
    - O excedente Ã© automaticamente escrito em disco
    - Protege o servidor contra uploads de vÃ¡rios GBs

---

### ğŸš¦ 3.3 Backpressure (Channel Buffering)

A leitura de disco Ã© mais rÃ¡pida que o processamento em CPU.
Sem controle, isso pode gerar acÃºmulo excessivo de dados na memÃ³ria.

=== "ImplementaÃ§Ã£o"

    jobs := make(chan []string, 1000)

=== "DecisÃ£o TÃ©cnica"

    - Channel com buffer de **1000 linhas**
    - Quando o buffer enche:
      - O leitor de disco Ã© automaticamente bloqueado
    - Cria **backpressure natural**, equilibrando I/O e CPU

!!! info "Resultado"

    O sistema se auto-regula conforme a velocidade do processamento, garantindo estabilidade e previsibilidade.

---

## ğŸ§µ 4. ConcorrÃªncia: Worker Pool

As **goroutines** do Go sÃ£o extremamente leves (~2 KB), muito menores que threads do sistema operacional (~1 MB).

!!! tip "EstratÃ©gia"

    - Um nÃºmero fixo de _workers_ Ã© iniciado (baseado no nÃºmero de CPUs)
    - Todos consomem linhas do mesmo channel
    - Se um worker ficar lento (ex.: regex pesada), os outros continuam processando
    **BenefÃ­cio:**
    âœ”ï¸ Melhor uso da CPU
    âœ”ï¸ Paralelismo real
    âœ”ï¸ Alta escalabilidade com baixo consumo de memÃ³ria

---

## ğŸ“¦ 5. DistribuiÃ§Ã£o: BinÃ¡rio Ãšnico (Embed)

Para simplificar o deploy e eliminar dependÃªncias externas (Nginx/Apache), utilizamos o **`embed` do Go (v1.16+)**.

=== "Como Funciona"

    Durante o `go build`, os arquivos estÃ¡ticos do frontend (React) sÃ£o embutidos diretamente no binÃ¡rio.
        //go:embed frontend/dist/\*
        var frontendFS embed.FS

=== "BenefÃ­cios"

    - Um Ãºnico arquivo executÃ¡vel
    - ContÃ©m:
      - API
      - Pipeline de processamento
      - Interface Web
    - Deploy simples, portÃ¡til e previsÃ­vel

---

!!! success "Resumo Final"

    O DataProfiler combina **streaming**, **concorrÃªncia eficiente** e **deploy simplificado** para processar Big Data em ambientes com recursos extremamente limitados.
