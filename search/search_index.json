{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"DataProfiler Enterprise <p>     An\u00e1lise de Qualidade e Perfilamento de Dados processando Gigabytes com consumo m\u00ednimo de RAM.   </p>        \ud83d\ude80 Come\u00e7ar Agora             Entender a Engenharia       O Problema: Big Data vs Hardware Limitado  \ud83d\ude80 Alta Performance <p>       Esque\u00e7a o erro <code>Out of Memory</code>. Nossa arquitetura l\u00ea arquivos maiores que a RAM dispon\u00edvel, utilizando buffers inteligentes e I/O n\u00e3o bloqueante. Processa 10GB com apenas 512MB de RAM.     </p> \ud83d\udee1\ufe0f SLA Autom\u00e1tico <p>       O sistema classifica automaticamente a qualidade das colunas (Ouro, Prata, Bronze) calculando a densidade de informa\u00e7\u00e3o e consist\u00eancia em tempo real para tomada de decis\u00e3o.     </p> \ud83d\udc41\ufe0f Seguran\u00e7a &amp; LGPD <p>       Detector de PII (Dados Pessoais) integrado. O sistema varre e alerta sobre CPF, E-mails e Cart\u00f5es de Cr\u00e9dito expostos para garantir conformidade.     </p> \ud83d\udce6 Single Binary <p>       Zero depend\u00eancias. O Backend (Go) e o Frontend (React) s\u00e3o compilados em um \u00fanico arquivo execut\u00e1vel <code>.exe</code>. Baixou, rodou, usou.     </p> \ud83e\udde0 Infer\u00eancia Inteligente <p>       Esque\u00e7a o mapeamento manual (`schema`). O algoritmo de Type Inference analisa amostras dos dados para detectar automaticamente se a coluna \u00e9 Inteiro, Decimal, Data ou Texto.     </p> \ud83d\udcca Interface &amp; Estat\u00edsticas <p>       Frontend em React + Material UI. Oferece DataGrid com pagina\u00e7\u00e3o nativa, filtros avan\u00e7ados e c\u00e1lculo autom\u00e1tico de estat\u00edsticas (M\u00e9dia, Mediana, Desvio Padr\u00e3o) em tempo real.     </p>  A Engenharia por tr\u00e1s do Streaming <p>O diferencial do DataProfiler \u00e9 a arquitetura Producer-Consumer. O dado flui atrav\u00e9s de canais concorrentes sem nunca ser carregado totalmente na mem\u00f3ria.</p> <pre><code>graph LR\n    A[Arquivo CSV Massivo] --&gt;|Stream Leitura| B(Go Reader / Buffer);\n    B --&gt;|Chunks de Dados| C{Canal de Distribui\u00e7\u00e3o};\n    C --&gt;|Worker 1| D[Valida\u00e7\u00e3o de Tipos];\n    C --&gt;|Worker 2| E[Regex PII];\n    C --&gt;|Worker 3| F[Estat\u00edstica];\n    D &amp; E &amp; F --&gt;|Agrega\u00e7\u00e3o| G[Relat\u00f3rio JSON];\n    G --&gt; H[Dashboard React];\n\n    style B fill:#3f51b5,stroke:#fff,stroke-width:2px,color:#fff\n    style H fill:#2196f3,stroke:#fff,stroke-width:2px,color:#fff</code></pre>"},{"location":"#pronto-para-usar-nao-requer-python-java-ou-docker-obrigatorio","title":"Pronto para usar? N\u00e3o requer Python, Java ou Docker obrigat\u00f3rio.","text":"<p> Baixar para Windows (.exe) </p> <p> Ver Decis\u00f5es de Arquitetura (ADR) </p>"},{"location":"decisoes/001-escolha-documentacao/","title":"Decis\u00e3o de Arquitetura 001: Stack de Documenta\u00e7\u00e3o","text":"<ul> <li>Status: Aceito</li> <li>Data: 06-01-2026</li> <li>Contexto: Engenharia &amp; Gest\u00e3o de Conhecimento</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#1-o-contexto-o-problema","title":"1. O Contexto (O Problema)","text":"<p>O projeto DataProfiler nasceu com um desafio at\u00edpico para softwares em fase inicial: a alta densidade de conhecimento pr\u00e9vio. Diferente de projetos que come\u00e7am com uma p\u00e1gina em branco, iniciamos o desenvolvimento com um legado de conhecimento bruto estimado em mais de 550 p\u00e1ginas de anota\u00e7\u00f5es t\u00e9cnicas, regras de neg\u00f3cio e estudos de viabilidade.</p> <p>Esse volume massivo de informa\u00e7\u00e3o trouxe riscos imediatos para a escalabilidade do projeto:</p> <ol> <li>Fragmenta\u00e7\u00e3o: O conhecimento estava disperso em arquivos de texto soltos e anota\u00e7\u00f5es pessoais, dificultando a consulta r\u00e1pida (\"Onde est\u00e1 aquela regra sobre Regex de CPF?\").</li> <li>Dessincronia: Manter a documenta\u00e7\u00e3o separada do c\u00f3digo (ex: em um Google Docs ou Word) criaria, inevitavelmente, uma documenta\u00e7\u00e3o obsoleta. \u00c0 medida que o c\u00f3digo Go evolu\u00edsse, o documento est\u00e1tico morreria.</li> <li>Complexidade de Manuten\u00e7\u00e3o: Gerenciar 550 p\u00e1ginas sem uma estrutura de navega\u00e7\u00e3o hier\u00e1rquica (Menu Lateral, Categorias) tornaria o consumo da informa\u00e7\u00e3o invi\u00e1vel para novos desenvolvedores ou stakeholders.</li> </ol>"},{"location":"decisoes/001-escolha-documentacao/#os-drivers-da-decisao-requisitos","title":"Os Drivers da Decis\u00e3o (Requisitos)","text":"<p>Para mitigar esses riscos, estabelecemos que a solu\u00e7\u00e3o de documenta\u00e7\u00e3o precisaria atender estritamente aos seguintes crit\u00e9rios de arquitetura:</p> <ul> <li>Filosofia \"Docs as Code\": A documenta\u00e7\u00e3o deve ser tratada como software. Ela deve viver no mesmo reposit\u00f3rio do c\u00f3digo fonte, passar por Code Review e ser versionada (Git).</li> <li>Versionamento (Git): Necessidade de rastrear a evolu\u00e7\u00e3o das decis\u00f5es. Se mudarmos a arquitetura do Backend amanh\u00e3, a documenta\u00e7\u00e3o deve ter um commit associado explicando o porqu\u00ea.</li> <li>Baixa Fric\u00e7\u00e3o de Escrita (Markdown): A ferramenta n\u00e3o poderia exigir conhecimentos complexos de HTML/CSS para escrever uma p\u00e1gina simples. O foco deve ser no conte\u00fado, n\u00e3o na diagrama\u00e7\u00e3o.</li> <li>Suporte a Diagramas: Devido \u00e0 complexidade dos fluxos de dados (Streaming, Channels, Goroutines), a ferramenta precisaria renderizar diagramas de arquitetura nativamente (ex: Mermaid.js) sem depender de imagens est\u00e1ticas <code>.png</code> que ficam desatualizadas.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#2-opcoes-consideradas","title":"2. Op\u00e7\u00f5es Consideradas","text":"<p>Para a implementa\u00e7\u00e3o da estrat\u00e9gia de \"Docs as Code\", avaliamos as duas principais ferramentas l\u00edderes de mercado. A an\u00e1lise focou no equil\u00edbrio entre manutenibilidade (facilidade de manter o sistema rodando) e produtividade (velocidade para migrar as 550 p\u00e1ginas de conte\u00fado legado).</p>"},{"location":"decisoes/001-escolha-documentacao/#opcao-a-docusaurus-metafacebook","title":"Op\u00e7\u00e3o A: Docusaurus (Meta/Facebook)","text":"<p>Ferramenta baseada em React/Node.js.</p> <ul> <li>Atratividade: Como nosso Frontend (Client) utiliza React, esta seria a escolha \"natural\" para manter a stack unificada. Permite customiza\u00e7\u00e3o visual infinita, tratando p\u00e1ginas como componentes.</li> <li>O Bloqueio: Introduz complexidade acidental. O Docusaurus exige que a documenta\u00e7\u00e3o seja tratada como uma aplica\u00e7\u00e3o React completa. Para um projeto onde o foco \u00e9 organizar regras de neg\u00f3cio complexas, gastar tempo \"programando o layout da documenta\u00e7\u00e3o\" foi considerado um desvio de prioridade.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#opcao-b-mkdocs-material-theme-escolhida","title":"Op\u00e7\u00e3o B: MkDocs + Material Theme (Escolhida)","text":"<p>Ferramenta baseada em Python, configurada via YAML.</p> <ul> <li>Atratividade: Filosofia \"Conte\u00fado Primeiro\". O motor transforma arquivos Markdown puros em um site est\u00e1tico sem necessidade de codifica\u00e7\u00e3o HTML/JS.</li> <li>O Diferencial: O tema Material for MkDocs oferece nativamente recursos de UX avan\u00e7ados (Busca Instant\u00e2nea, Dark Mode, Navega\u00e7\u00e3o em Abas) que no Docusaurus exigiriam configura\u00e7\u00e3o manual ou plugins.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#criterios-de-desempate-matriz-de-decisao","title":"Crit\u00e9rios de Desempate (Matriz de Decis\u00e3o)","text":"Crit\u00e9rio Docusaurus (React) MkDocs (Python) Vencedor para o DataProfiler Configura\u00e7\u00e3o Imperativa (Code/JSX) Declarativa (YAML) MkDocs Curva de Aprendizado M\u00e9dia (Exige saber React) Baixa (Apenas Markdown) MkDocs Diagramas Plugins externos Nativo (Mermaid.js via Superfences) MkDocs Objetivo Criar portais customizados Organizar conhecimento denso MkDocs <p>Veredito: A escolha pelo MkDocs foi t\u00e9cnica e estrat\u00e9gica. Dado o volume de 550+ t\u00f3picos, a prioridade absoluta \u00e9 a velocidade de escrita e organiza\u00e7\u00e3o hier\u00e1rquica, sacrificando a liberdade criativa de design em prol de uma estrutura r\u00edgida, por\u00e9m funcional e padronizada.</p>"},{"location":"decisoes/001-escolha-documentacao/#3-a-solucao-tecnica-implementacao","title":"3. A Solu\u00e7\u00e3o T\u00e9cnica (Implementa\u00e7\u00e3o)","text":"<p>A escolha da ferramenta foi apenas o primeiro passo. A implementa\u00e7\u00e3o pr\u00e1tica em ambiente Windows revelou desafios de configura\u00e7\u00e3o que poderiam prejudicar a experi\u00eancia do desenvolvedor (DX) e dificultar o onboarding de novos membros no futuro.</p>"},{"location":"decisoes/001-escolha-documentacao/#31-o-desafio-do-ambiente-the-path-saga","title":"3.1 O Desafio do Ambiente (The PATH Saga)","text":"<p>Ao instalar o MkDocs via <code>pip</code> no Windows, o execut\u00e1vel frequentemente n\u00e3o \u00e9 adicionado automaticamente \u00e0s vari\u00e1veis de ambiente (PATH).</p> <ul> <li>O Sintoma: Ao digitar <code>mkdocs serve</code> no terminal, o sistema retornava o erro: \"O termo 'mkdocs' n\u00e3o \u00e9 reconhecido...\".</li> <li>A Solu\u00e7\u00e3o Fr\u00e1gil: Poder\u00edamos editar manualmente as Vari\u00e1veis de Ambiente do Windows.</li> <li>O Risco: Isso cria uma depend\u00eancia da configura\u00e7\u00e3o da m\u00e1quina local (\"Works on my machine\"). Se formatarmos o PC, perdemos a capacidade de rodar a doc.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#32-a-camada-de-abstracao-makefile","title":"3.2 A Camada de Abstra\u00e7\u00e3o (Makefile)","text":"<p>Para resolver a fragilidade do ambiente, decidimos n\u00e3o invocar o bin\u00e1rio do MkDocs diretamente. Em vez disso, utilizamos o <code>Makefile</code> (j\u00e1 presente no projeto devido ao Go) como um \"controle remoto\" ou wrapper.</p> <p>Adotamos a estrat\u00e9gia de invocar o m\u00f3dulo Python diretamente (<code>python -m mkdocs</code>). Isso garante que, se o Python estiver instalado, a documenta\u00e7\u00e3o vai rodar, ignorando completamente se o <code>mkdocs.exe</code> est\u00e1 no PATH ou n\u00e3o.</p>"},{"location":"decisoes/001-escolha-documentacao/#33-snippet-de-implementacao","title":"3.3 Snippet de Implementa\u00e7\u00e3o","text":"<p>Abaixo, o trecho do <code>Makefile</code> que padroniza os comandos de documenta\u00e7\u00e3o. Note a simplicidade exposta para o usu\u00e1rio final versus a robustez do comando real executado.</p> <pre><code># ==============================================================================\n# DOCUMENTATION (Docs as Code)\n# ==============================================================================\n\n# Instala as depend\u00eancias listadas no requirements.txt (MkDocs + Tema Material + Plugins)\ndocs-install:\n pip install -r docs/requirements.txt\n\n# Roda o servidor local com Hot-Reload (Atualiza ao salvar o arquivo)\n# Uso: python -m mkdocs garante execu\u00e7\u00e3o mesmo sem PATH configurado no Windows\ndocs-serve:\n python -m mkdocs serve\n\n# Compila o site est\u00e1tico para a pasta \"site/\" (Usado antes do deploy)\ndocs-build:\n python -m mkdocs build\n\n# Faz o deploy manual para o GitHub Pages\ndocs-deploy:\n python -m mkdocs gh-deploy --force\n</code></pre> <p>Resultado: O desenvolvedor n\u00e3o precisa saber comandos Python ou configurar PATHs complexos. Ele apenas digita make docs-serve e o ambiente funciona. Reduzimos a carga cognitiva e aumentamos a confiabilidade do processo.</p>"},{"location":"decisoes/001-escolha-documentacao/#4-diagramas-e-visualizacao-diagrams-as-code","title":"4. Diagramas e Visualiza\u00e7\u00e3o (Diagrams as Code)","text":"<p>Uma documenta\u00e7\u00e3o de engenharia robusta depende de fluxogramas e diagramas de arquitetura claros. No entanto, o m\u00e9todo tradicional (criar imagens em ferramentas externas como Visio ou Lucidchart, exportar como <code>.png</code> e colar no Markdown) gera um D\u00e9bito T\u00e9cnico de Documenta\u00e7\u00e3o imediato:</p> <ul> <li>Imagens bin\u00e1rias n\u00e3o s\u00e3o version\u00e1veis: O Git n\u00e3o consegue mostrar o \"diff\" (o que mudou) dentro de uma imagem PNG.</li> <li>Obsolesc\u00eancia R\u00e1pida: Se a l\u00f3gica do c\u00f3digo muda, o diagrama torna-se \"mentiroso\" pois o esfor\u00e7o para recriar a imagem \u00e9 alto.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#41-a-decisao-mermaidjs","title":"4.1 A Decis\u00e3o: Mermaid.js","text":"<p>Para resolver isso, adotamos o Mermaid.js, uma ferramenta que renderiza gr\u00e1ficos vetoriais diretamente no navegador a partir de defini\u00e7\u00f5es de texto simples. Isso estende a filosofia \"Docs as Code\" para a parte visual.</p> <p>Comparativo de Manuten\u00e7\u00e3o:</p> <ul> <li>Legado (Imagem): Abrir software gr\u00e1fico -&gt; Editar -&gt; Exportar -&gt; Substituir arquivo -&gt; Commit.</li> <li>Atual (Mermaid): Editar texto no Markdown -&gt; Commit.</li> </ul> <p>Exemplo Pr\u00e1tico: Ao escrevermos o seguinte bloco de c\u00f3digo:</p> <p>mermaid graph LR A[Usu\u00e1rio] --&gt;|Upload| B(Go Backend) B --&gt;|Processa| C{Sucesso?} C --&gt;|Sim| D[Retorna JSON] C --&gt;|N\u00e3o| E[Retorna Erro]</p> <pre><code>    graph LR\n      A[Usu\u00e1rio] --&gt;|Upload| B(Go Backend)\n      B --&gt;|Processa| C{Sucesso?}\n      C --&gt;|Sim| D[Retorna JSON]\n      C --&gt;|N\u00e3o| E[Retorna Erro]</code></pre> <p>O MkDocs intercepta esse bloco e desenha o fluxograma automaticamente na tela do usu\u00e1rio final.</p>"},{"location":"decisoes/001-escolha-documentacao/#42-configuracao-tecnica","title":"4.2 Configura\u00e7\u00e3o T\u00e9cnica","text":"<p>Para que o MkDocs entenda essa sintaxe especial (e n\u00e3o a trate como c\u00f3digo comum), realizamos duas configura\u00e7\u00f5es de infraestrutura:</p> <ol> <li>No Build (<code>mkdocs.yml</code>): Ativa\u00e7\u00e3o da extens\u00e3o <code>pymdownx.superfences</code>. \u00c9 ela que permite injetar scripts (como o do Mermaid) dentro de blocos de c\u00f3digo cercados (fences).</li> <li>No Editor (<code>.vscode/settings.json</code>): Ajuste das configura\u00e7\u00f5es do workspace para que o linter (verificador de sintaxe) do Markdown entenda que <code>mermaid</code> \u00e9 uma linguagem v\u00e1lida, evitando falsos alertas de erro durante a escrita.</li> </ol>"},{"location":"decisoes/001-escolha-documentacao/#5-estrategia-de-deploy-cicd","title":"5. Estrat\u00e9gia de Deploy (CI/CD)","text":"<p>Para garantir que a documenta\u00e7\u00e3o esteja acess\u00edvel globalmente para stakeholders e n\u00e3o apenas na m\u00e1quina local do desenvolvedor, definimos uma estrat\u00e9gia de publica\u00e7\u00e3o baseada em hospedagem est\u00e1tica.</p>"},{"location":"decisoes/001-escolha-documentacao/#51-infraestrutura-github-pages","title":"5.1 Infraestrutura: GitHub Pages","text":"<p>Optamos pelo GitHub Pages como plataforma de hospedagem.</p> <ul> <li>Custo Zero: Integrado ao plano gratuito do GitHub.</li> <li>HTTPS Nativo: Seguran\u00e7a autom\u00e1tica sem configura\u00e7\u00e3o de certificados.</li> <li>Separa\u00e7\u00e3o de Responsabilidades (Branching Strategy):</li> <li>Branch <code>main</code>: Cont\u00e9m a Fonte da Verdade (C\u00f3digo Fonte + Markdown Bruto).</li> <li>Branch <code>gh-pages</code>: Cont\u00e9m apenas o Artefato Compilado (HTML/CSS/JS final). Essa branch \u00e9 \u00f3rf\u00e3 e gerenciada automaticamente pelo script de deploy.</li> </ul>"},{"location":"decisoes/001-escolha-documentacao/#52-mecanismo-de-deploy-automacao","title":"5.2 Mecanismo de Deploy (Automa\u00e7\u00e3o)","text":"<p>Embora o GitHub Actions seja o padr\u00e3o de mercado para CI/CD, para esta fase inicial do projeto, decidimos, arquiteturalmente, n\u00e3o automatizar o deploy a cada commit.</p> <p>Decis\u00e3o: Deploy Manual Controlado (\"Gatekeeper Strategy\") Implementamos o comando <code>make docs-deploy</code> no Makefile.</p> <ul> <li>O Risco da Automa\u00e7\u00e3o Total: Um pipeline de \"Deploy on Push\" publicaria imediatamente qualquer altera\u00e7\u00e3o salva. Isso cria o risco de expor rascunhos incompletos, se\u00e7\u00f5es \"To-Do\" ou documenta\u00e7\u00e3o de funcionalidades que ainda n\u00e3o foram mergeadas no c\u00f3digo principal.</li> <li>A Vantagem do Manual: O deploy manual devolve o controle ao engenheiro. A documenta\u00e7\u00e3o s\u00f3 \u00e9 atualizada em produ\u00e7\u00e3o quando o desenvolvedor explicitamente valida o conte\u00fado localmente (<code>make docs-serve</code>) e decide que a vers\u00e3o est\u00e1 est\u00e1vel para consumo p\u00fablico.</li> </ul> <p>Comando T\u00e9cnico: O Makefile executa: <code>python -m mkdocs gh-deploy --force</code> (Nota: A flag <code>--force</code> \u00e9 utilizada intencionalmente para sobrescrever o hist\u00f3rico da branch <code>gh-pages</code>, mantendo o reposit\u00f3rio leve e focado apenas na vers\u00e3o atual do site).</p>"},{"location":"engenharia/arquitetura-streaming/","title":"\ud83c\udfd7\ufe0f Arquitetura de Streaming e Performance","text":"<p>Esta se\u00e7\u00e3o descreve as decis\u00f5es de engenharia que permitem ao DataProfiler processar arquivos massivos (GBs) mantendo uma pegada de mem\u00f3ria m\u00ednima (MBs). A arquitetura resolve o problema cl\u00e1ssico de Big Data em Hardware Pequeno.</p>"},{"location":"engenharia/arquitetura-streaming/#1-o-desafio-de-engenharia","title":"\ud83c\udfaf 1. O Desafio de Engenharia","text":"<p>Em abordagens tradicionais de Ci\u00eancia de Dados (como Python/Pandas ou R), o padr\u00e3o \u00e9 carregar todo o dataset na mem\u00f3ria RAM (In-Memory Processing).</p> <p>Cen\u00e1rio Tradicional</p> <ul> <li>Arquivo de entrada: CSV de 10 GB</li> <li>Infraestrutura: Container serverless (Render, AWS Lambda) com 512 MB de RAM</li> <li>Resultado: Processo encerrado com erro <code>OOMKilled</code> antes da an\u00e1lise come\u00e7ar</li> </ul> <p>Abordagem DataProfiler</p> <p>Adotamos uma arquitetura de Streaming Pipeline. Em vez de carregar o dataset inteiro, os dados s\u00e3o tratados como um fluxo cont\u00ednuo:</p> <p>L\u00ea \u2192 Processa \u2192 Descarta da mem\u00f3ria</p>"},{"location":"engenharia/arquitetura-streaming/#2-pipeline-de-processamento","title":"\ud83d\udd04 2. Pipeline de Processamento","text":"<p>O fluxo de dados segue o padr\u00e3o Producer\u2013Consumer, utilizando as primitivas de concorr\u00eancia do Go (<code>Channels</code> e <code>Goroutines</code>).</p> <pre><code>graph LR\n    User[Usu\u00e1rio] --&gt;|Upload HTTP Multipart| Server[Servidor Go]\n\n    subgraph \"Camada de Ingest\u00e3o (I/O)\"\n        Server --&gt;|Stream 32MB chunks| Disk[Disco Tempor\u00e1rio]\n        Disk --&gt;|Buffer 1MB| Reader[Leitor Bufio]\n        Reader --&gt;|Parse CSV| Parser[CSV Parser]\n    end\n\n    subgraph \"Camada de Processamento (Concorr\u00eancia)\"\n        Parser --&gt;|Envia Linha| Chan{Channel Buffer: 1000}\n\n        Chan --&gt;|Consome| W1[Worker 1: Infer\u00eancia]\n        Chan --&gt;|Consome| W2[Worker 2: Estat\u00edstica]\n        Chan --&gt;|Consome| W3[Worker 3: Regex PII]\n    end\n\n    subgraph \"Camada de Agrega\u00e7\u00e3o\"\n        W1 &amp; W2 &amp; W3 --&gt;|Resultados Parciais| Agg[Acumulador]\n        Agg --&gt;|JSON Final| UI[Frontend React]\n    end</code></pre>"},{"location":"engenharia/arquitetura-streaming/#3-tuning-de-performance","title":"\u2699\ufe0f 3. Tuning de Performance","text":""},{"location":"engenharia/arquitetura-streaming/#os-numeros-magicos","title":"Os \u201cN\u00fameros M\u00e1gicos\u201d","text":"<p>A efici\u00eancia do sistema depende do ajuste preciso de buffers e limites. Abaixo est\u00e3o as principais decis\u00f5es t\u00e9cnicas.</p>"},{"location":"engenharia/arquitetura-streaming/#31-otimizacao-de-io-de-disco-bufio","title":"\ud83d\udcc0 3.1 Otimiza\u00e7\u00e3o de I/O de Disco (<code>bufio</code>)","text":"<p>Ler dados do disco \u00e9 uma opera\u00e7\u00e3o lenta. A leitura byte a byte gera milh\u00f5es de syscalls, degradando a performance.</p> Implementa\u00e7\u00e3oDecis\u00e3o T\u00e9cnica <p>bufio.NewReaderSize(file, 1024*1024)</p> <ul> <li>Buffer de 1 MB</li> <li>Reduz drasticamente o n\u00famero de acessos ao disco</li> <li>Aumenta o throughput de leitura</li> </ul>"},{"location":"engenharia/arquitetura-streaming/#32-limite-de-upload-multipart-form","title":"\ud83d\udce4 3.2 Limite de Upload (Multipart Form)","text":"<p>Uploads grandes podem esgotar a mem\u00f3ria do servidor se n\u00e3o houver controle.</p> Implementa\u00e7\u00e3oDecis\u00e3o T\u00e9cnica <pre><code>r.ParseMultipartForm(32 &lt;&lt; 20)\n</code></pre> <ul> <li>Apenas 32 MB permanecem em RAM</li> <li>O excedente \u00e9 automaticamente escrito em disco</li> <li>Protege o servidor contra uploads de v\u00e1rios GBs</li> </ul>"},{"location":"engenharia/arquitetura-streaming/#33-backpressure-channel-buffering","title":"\ud83d\udea6 3.3 Backpressure (Channel Buffering)","text":"<p>A leitura de disco \u00e9 mais r\u00e1pida que o processamento em CPU. Sem controle, isso pode gerar ac\u00famulo excessivo de dados na mem\u00f3ria.</p> Implementa\u00e7\u00e3oDecis\u00e3o T\u00e9cnica <p>jobs := make(chan []string, 1000)</p> <ul> <li>Channel com buffer de 1000 linhas</li> <li>Quando o buffer enche:</li> <li>O leitor de disco \u00e9 automaticamente bloqueado</li> <li>Cria backpressure natural, equilibrando I/O e CPU</li> </ul> <p>Resultado</p> <p>O sistema se auto-regula conforme a velocidade do processamento, garantindo estabilidade e previsibilidade.</p>"},{"location":"engenharia/arquitetura-streaming/#4-concorrencia-worker-pool","title":"\ud83e\uddf5 4. Concorr\u00eancia: Worker Pool","text":"<p>As goroutines do Go s\u00e3o extremamente leves (~2 KB), muito menores que threads do sistema operacional (~1 MB).</p> <p>Estrat\u00e9gia</p> <ul> <li>Um n\u00famero fixo de workers \u00e9 iniciado (baseado no n\u00famero de CPUs)</li> <li>Todos consomem linhas do mesmo channel</li> <li>Se um worker ficar lento (ex.: regex pesada), os outros continuam processando Benef\u00edcio: \u2714\ufe0f Melhor uso da CPU \u2714\ufe0f Paralelismo real \u2714\ufe0f Alta escalabilidade com baixo consumo de mem\u00f3ria</li> </ul>"},{"location":"engenharia/arquitetura-streaming/#5-distribuicao-binario-unico-embed","title":"\ud83d\udce6 5. Distribui\u00e7\u00e3o: Bin\u00e1rio \u00danico (Embed)","text":"<p>Para simplificar o deploy e eliminar depend\u00eancias externas (Nginx/Apache), utilizamos o <code>embed</code> do Go (v1.16+).</p> Como FuncionaBenef\u00edcios <p>Durante o <code>go build</code>, os arquivos est\u00e1ticos do frontend (React) s\u00e3o embutidos diretamente no bin\u00e1rio.     //go:embed frontend/dist/*     var frontendFS embed.FS</p> <ul> <li>Um \u00fanico arquivo execut\u00e1vel</li> <li>Cont\u00e9m:</li> <li>API</li> <li>Pipeline de processamento</li> <li>Interface Web</li> <li>Deploy simples, port\u00e1til e previs\u00edvel</li> </ul> <p>Resumo Final</p> <p>O DataProfiler combina streaming, concorr\u00eancia eficiente e deploy simplificado para processar Big Data em ambientes com recursos extremamente limitados.</p>"},{"location":"guia-usuario/funcionalidades/","title":"Regras de Neg\u00f3cio e Funcionalidades","text":"<p>O diferencial do DataProfiler \u00e9 sua capacidade de \"entender\" o dado, n\u00e3o apenas l\u00ea-lo. Abaixo detalhamos os algoritmos de infer\u00eancia.</p>"},{"location":"guia-usuario/funcionalidades/#1-calculo-de-sla-nivel-de-qualidade","title":"1. C\u00e1lculo de SLA (N\u00edvel de Qualidade)","text":"<p>O sistema atribui um selo de qualidade para cada coluna processada. Isso permite que engenheiros de dados decidam rapidamente se aquela coluna pode ser usada em um modelo de Machine Learning ou Dashboard.</p>"},{"location":"guia-usuario/funcionalidades/#a-logica-matematica","title":"A L\u00f3gica Matem\u00e1tica","text":"<p>O c\u00e1lculo \u00e9 baseado na Densidade de Informa\u00e7\u00e3o. O sistema contabiliza, em tempo real, quantos valores s\u00e3o considerados \"sujos\" (Nulos, Vazios, <code>NA</code>, <code>NULL</code>).</p> <p>$$\\text{Score} = \\frac{\\text{Total Linhas} - \\text{Linhas Sujas}}{\\text{Total Linhas}} \\times 100$$</p>"},{"location":"guia-usuario/funcionalidades/#classificacao","title":"Classifica\u00e7\u00e3o","text":"Selo Crit\u00e9rio Interpreta\u00e7\u00e3o \ud83e\udd47 Ouro Score \u2265 99% Alta Confiabilidade. Dados praticamente \u00edntegros. Seguros para chaves prim\u00e1rias ou m\u00e9tricas financeiras. \ud83e\udd48 Prata 95% \u2264 Score &lt; 99% Confiabilidade M\u00e9dia. Dados \u00fateis para an\u00e1lises de tend\u00eancia, mas requerem aten\u00e7\u00e3o em casos de borda. \ud83e\udd49 Bronze Score &lt; 95% Baixa Qualidade. Requer tratamento (imputa\u00e7\u00e3o de dados) antes do uso. Alto risco de vi\u00e9s."},{"location":"guia-usuario/funcionalidades/#2-deteccao-de-sensibilidade-lgpdgdpr","title":"2. Detec\u00e7\u00e3o de Sensibilidade (LGPD/GDPR)","text":"<p>Para garantir conformidade com leis de prote\u00e7\u00e3o de dados, o DataProfiler escaneia o conte\u00fado em busca de PII (Personally Identifiable Information).</p> <p>O algoritmo funciona em duas camadas:</p> <ol> <li>An\u00e1lise de Cabe\u00e7alho: Verifica se o nome da coluna sugere dados sens\u00edveis (ex: \"cpf_cliente\", \"email_contato\").</li> <li>An\u00e1lise de Conte\u00fado (Regex): Verifica se os valores batem com padr\u00f5es conhecidos.</li> </ol>"},{"location":"guia-usuario/funcionalidades/#padroes-detectados","title":"Padr\u00f5es Detectados","text":"<p>Aten\u00e7\u00e3o</p> <p>Se uma coluna for marcada como Sens\u00edvel, o \u00edcone \ud83d\udee1\ufe0f aparecer\u00e1 no relat\u00f3rio. Recomenda-se aplicar hashing ou mascaramento nesses dados.</p> <ul> <li>CPF (Brasil): Valida\u00e7\u00e3o de formato <code>111.222.333-44</code> ou <code>11122233344</code>.</li> <li>E-mail: Padr\u00e3o RFC 5322 (<code>usuario@dominio.com</code>).</li> <li>Cart\u00e3o de Cr\u00e9dito: Detec\u00e7\u00e3o de sequ\u00eancias num\u00e9ricas compat\u00edveis com PANs (Luhn Algorithm check b\u00e1sico).</li> <li>Telefone: Padr\u00f5es globais E.164 e nacionais.</li> </ul>"},{"location":"guia-usuario/funcionalidades/#3-inferencia-de-tipos-polimorfismo","title":"3. Infer\u00eancia de Tipos (Polimorfismo)","text":"<p>Como o CSV \u00e9 um formato sem tipo (tudo \u00e9 texto), o DataProfiler realiza uma infer\u00eancia estat\u00edstica. Ele l\u00ea uma amostragem dos dados e tenta \"promover\" o tipo para o mais espec\u00edfico poss\u00edvel.</p> <p>Ordem de Tentativa:</p> <ol> <li>Integer: \u00c9 um n\u00famero inteiro? (ex: <code>42</code>)</li> <li>Float: \u00c9 decimal? (ex: <code>42.5</code> ou <code>42,5</code>) -&gt; Suporta ponto e v\u00edrgula como decimal.</li> <li>Boolean: \u00c9 l\u00f3gico? (ex: <code>true</code>, <code>1</code>, <code>sim</code>, <code>yes</code>)</li> <li>Date: \u00c9 data? (ex: <code>2023-01-01</code>, <code>01/01/2023</code>) -&gt; Suporta ISO8601 e BR.</li> <li>String: Se falhar em tudo, \u00e9 texto.</li> </ol>"},{"location":"guia-usuario/instalacao/","title":"Guia de Instala\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<p>O DataProfiler foi projetado para ser agn\u00f3stico de plataforma. Oferecemos tr\u00eas m\u00e9todos de execu\u00e7\u00e3o, variando do \"clique e use\" (para usu\u00e1rios finais) at\u00e9 a compila\u00e7\u00e3o total (para desenvolvedores).</p>"},{"location":"guia-usuario/instalacao/#metodo-1-executavel-recomendado","title":"M\u00e9todo 1: Execut\u00e1vel (Recomendado)","text":"<p>A forma mais simples de utilizar o DataProfiler \u00e9 atrav\u00e9s do conceito de Single Binary. O Backend (Go) e o Frontend (React) foram compilados em um \u00fanico arquivo. N\u00e3o \u00e9 necess\u00e1rio instalar Java, Python ou Node.js.</p>"},{"location":"guia-usuario/instalacao/#windows","title":"Windows","text":"<ol> <li>Acesse a P\u00e1gina de Releases do projeto.</li> <li>Baixe o arquivo <code>dataprofiler-windows-amd64.exe</code>.</li> <li>D\u00ea um duplo clique no arquivo baixado.</li> <li>O terminal se abrir\u00e1 e, em seguida, seu navegador padr\u00e3o abrir\u00e1 automaticamente em <code>http://localhost:8080</code>.</li> </ol> <p>Alerta do Windows Defender</p> <p>Como este \u00e9 um software open-source n\u00e3o assinado digitalmente (o que custa caro), o Windows pode exibir a tela \"O Windows protegeu o computador\".</p> <p>Isso \u00e9 um falso positivo. Para prosseguir:</p> <ol> <li>Clique em \"Mais informa\u00e7\u00f5es\".</li> <li>Clique no bot\u00e3o \"Executar assim mesmo\".</li> </ol>"},{"location":"guia-usuario/instalacao/#linux-macos","title":"Linux / macOS","text":"<ol> <li>Acesse a P\u00e1gina de Releases do projeto.</li> <li>Baixe o arquivo <code>dataprofiler-linux-amd64</code> (ou <code>darwin</code> para Mac).</li> <li>Abra o terminal na pasta do download e d\u00ea permiss\u00e3o de execu\u00e7\u00e3o:</li> </ol> <pre><code>chmod +x dataprofiler-linux-amd64\n</code></pre> <ol> <li>Execute o programa:</li> </ol> <pre><code>./dataprofiler-linux-amd64\n</code></pre>"},{"location":"guia-usuario/instalacao/#metodo-2-docker-ambiente-isolado","title":"M\u00e9todo 2: Docker (Ambiente Isolado)","text":"<p>Se voc\u00ea prefere n\u00e3o rodar bin\u00e1rios diretamente no seu sistema operacional, disponibilizamos uma imagem Docker oficial. Este m\u00e9todo garante que o ambiente seja id\u00eantico ao de produ\u00e7\u00e3o.</p> <p>Pr\u00e9-requisitos: Docker e Docker Compose instalados.</p> <p>Crie um arquivo <code>docker-compose.yml</code>:</p> <pre><code>title=\"docker-compose.yml\"\nversion: \"3.8\"\nservices:\n  app:\n    image: jgustavocn/dataprofiler:latest\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - ./uploads:/app/uploads\n</code></pre> <p>No terminal, execute:</p> <pre><code>docker compose up -d\n</code></pre> <p>O sistema estar\u00e1 dispon\u00edvel em: http://localhost:8080</p>"},{"location":"guia-usuario/instalacao/#metodo-3-compilando-do-codigo-para-desenvolvedores","title":"M\u00e9todo 3: Compilando do C\u00f3digo (Para Desenvolvedores)","text":"<p>Se voc\u00ea deseja contribuir com o c\u00f3digo ou testar funcionalidades experimentais, siga os passos de compila\u00e7\u00e3o manual.</p>"},{"location":"guia-usuario/instalacao/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Go: Vers\u00e3o 1.22 ou superior.</li> <li>Node.js: Vers\u00e3o 20 (LTS) ou superior.</li> <li>Make: (Opcional, mas recomendado).</li> </ul>"},{"location":"guia-usuario/instalacao/#passo-a-passo","title":"Passo a Passo","text":"<ol> <li>Clone o reposit\u00f3rio:</li> </ol> <pre><code>git clone https://github.com/JGustavoCN/dataprofiler.git\ncd dataprofiler\n</code></pre> <ol> <li>Instale as depend\u00eancias (Backend e Frontend):    Utilizamos o Makefile para automatizar a instala\u00e7\u00e3o das libs do Go e os pacotes npm do React.</li> </ol> <pre><code>make setup\n</code></pre> <ol> <li>Execute em modo de desenvolvimento:    Este comando roda o Backend com Hot-Reload (Air) e o Frontend em modo dev.</li> </ol> <pre><code>make run\n</code></pre>"},{"location":"guia-usuario/instalacao/#troubleshooting-resolucao-de-problemas","title":"\ud83d\udd27 Troubleshooting (Resolu\u00e7\u00e3o de Problemas)","text":""},{"location":"guia-usuario/instalacao/#erro-address-already-in-use-porta-8080-ocupada","title":"Erro: \"Address already in use\" (Porta 8080 ocupada)","text":"<p>Se voc\u00ea j\u00e1 tiver outro servi\u00e7o rodando na porta <code>8080</code> (comum em desenvolvedores Java/Tomcat), o DataProfiler n\u00e3o iniciar\u00e1.</p> <p>Solu\u00e7\u00e3o: Defina a vari\u00e1vel de ambiente <code>PORT</code> antes de executar.</p>"},{"location":"guia-usuario/instalacao/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code>$env:PORT=\"9090\"; .\\dataprofiler.exe\n</code></pre>"},{"location":"guia-usuario/instalacao/#linux-mac","title":"Linux / Mac","text":"<pre><code>PORT=9090 ./dataprofiler\n</code></pre>"},{"location":"guia-usuario/instalacao/#erro-tela-branca-ou-connection-refused","title":"Erro: Tela Branca ou \"Connection Refused\"","text":"<p>Certifique-se de que o backend Go est\u00e1 rodando. O Frontend React depende da API para funcionar. Se voc\u00ea estiver rodando via c\u00f3digo fonte, garanta que ambos os terminais (Go e Node) estejam ativos.</p>"}]}